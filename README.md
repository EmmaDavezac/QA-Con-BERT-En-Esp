# QA-Con-BERT-En-Esp

Este repositorio es una modificación del repositorio https://github.com/codificandobits/Comprension_de_texto_con_BERT y se basa en el modelo 'distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es' de Hugging Face. Siguiendo el video tutorial https://www.youtube.com/watch?v=iPrwWtVl0LM, hemos adaptado y mejorado la implementación original para proporcionar una generación de respuestas mejorada utilizando este modelo pre-entrenado.

El modelo 'distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es' es una versión compacta y optimizada de BERT para el idioma español, que ha sido previamente ajustada para responder preguntas basadas en el conjunto de datos SQuAD en español. 

El repositorio, proporcionamos el código fuente y los recursos necesarios para implementar de forma rapida y efectiva este modelo.

Ya sea que estés desarrollando una aplicación de preguntas y respuestas, un chatbot o cualquier otra aplicación que requiera generación de respuestas precisas, este repositorio te proporcionará una base sólida para comenzar.
